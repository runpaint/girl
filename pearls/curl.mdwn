Download URLs, interact with web services, and debug HTTP transactions.

* `curl url` - Performs a GET request on URL `url` and displays the response
body.
  * `-u user:pass` - Authenticates using HTTP Auth with username `user` and password `pass`.
  * `-I` - Displays only the document headers.
  * `-o file` - Writes the response body to file `file` instead of STDOUT.
  * `-O` - Writes the response body to a file with the same name as the remote
file.
  * `-s` - Don't show the progress meter (statistics about the request).
  * `-d "name=value"` - POSTs "name=value" to URL. If this option is given
multiple times, the data will be concatenated with ampersands (_&_). 
  * `-d "name=@value` - As above, but the _@_ prefix indicates that
_value_ is a filename whose contents should be uploaded.
  * `-X method` - Uses HTTP method `method` instead of GET.
  * `--limit-rate speed` - Download at an average speed of `speed`. For
example: _20k_ (20 kilobytes), _4M_ (4 megabytes), _2G_ (2 gigabytes).

## URLs

* If multiple URLs are given on the command line they are fetched
sequentially.
* If the protocol isn't supplied, it's guessed.

Sets of URLs can be generated by specifying regular-expression-like patterns.

* Lists enclosed in braces are enumerated when they appear in URLs. For
example, _http://en.wikipedia.org/wiki/{Ruby,Perl}_  expands to
_http://en.wikipedia.org/wiki/Ruby_ and _http://en.wikipedia.org/Perl_ . So,
`curl -O http://{en,de}.wikipedia.org/wiki/{Ruby,Perl}` downloads the Ruby and
Perl articles in both English and German.
* Alphanumeric ranges enclosed in square brackets are also supported. For
example, `curl -o '#1.html' "http://en.wikipedia.org/wiki/[0-9]_(number)"`
downloads _http://en.wikipedia.org/wiki/0\_(number)_ to _0.html_ , and so on up
to 9. Ranges can be alphabetic as well, e.g. _[a-f]_ .

## Examples
* `curl -u user:pass -o bookmarks.xml
https://api.del.icio.us/v1/posts/all` - Login to the
[del.icio.us](http://del.icio.us/) API over HTTPS with username `user` and
password `pass`, then download https://api.del.icio.us/v1/posts/all to a file
named _bookmarks.html_ .
* `curl -u user:pass -d status="Text" http://twitter.com/statuses/update.xml`
- Post a 'tweet' to [Twitter](http://twitter.com/) with the text _Text_ using
  username `user` and password `pass`.
* `curl -s
ftp://ftp.kernel.org/pub/linux/docs/man-pages/man-pages-3.16.tar.bz2 | tar jxf
-` - Download _man-pages-3.16.tar.bz2_ over FTP then extract the archive with
`tar`.
